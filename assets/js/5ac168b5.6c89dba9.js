"use strict";(self.webpackChunkwww_cloudcarbonfootprint_org=self.webpackChunkwww_cloudcarbonfootprint_org||[]).push([[814],{3905:function(e,t,n){n.d(t,{Zo:function(){return p},kt:function(){return m}});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function u(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=a.createContext({}),s=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},p=function(e){var t=s(e.components);return a.createElement(l.Provider,{value:t},e.children)},c="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},g=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,l=e.parentName,p=u(e,["components","mdxType","originalType","parentName"]),c=s(n),g=r,m=c["".concat(l,".").concat(g)]||c[g]||d[g]||o;return n?a.createElement(m,i(i({ref:t},p),{},{components:n})):a.createElement(m,i({ref:t},p))}));function m(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,i=new Array(o);i[0]=g;var u={};for(var l in t)hasOwnProperty.call(t,l)&&(u[l]=t[l]);u.originalType=e,u[c]="string"==typeof e?e:r,i[1]=u;for(var s=2;s<o;s++)i[s]=n[s];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}g.displayName="MDXCreateElement"},4618:function(e,t,n){n.r(t),n.d(t,{assets:function(){return l},contentTitle:function(){return i},default:function(){return c},frontMatter:function(){return o},metadata:function(){return u},toc:function(){return s}});var a=n(3117),r=(n(7294),n(3905));const o={id:"creating-a-lookup-table",title:"Creating a Lookup Table",slug:"/creating-a-lookup-table",sidebar_position:7},i=void 0,u={unversionedId:"GettingStarted/creating-a-lookup-table",id:"GettingStarted/creating-a-lookup-table",title:"Creating a Lookup Table",description:"In order to support the big data processing requirements that some organizations have, it may be more practical or efficient for you to compute carbon metrics within your existing processing. To do so, we support the generation of a lookup table that can be utilized as an additional step in your pipeline.",source:"@site/docs/GettingStarted/CreatingALookupTable.md",sourceDirName:"GettingStarted",slug:"/creating-a-lookup-table",permalink:"/docs/creating-a-lookup-table",draft:!1,tags:[],version:"current",sidebarPosition:7,frontMatter:{id:"creating-a-lookup-table",title:"Creating a Lookup Table",slug:"/creating-a-lookup-table",sidebar_position:7},sidebar:"defaultSidebar",previous:{title:"Running the CLI",permalink:"/docs/running-the-cli"},next:{title:"Deploying",permalink:"/docs/deploying"}},l={},s=[{value:"Example queries to create input CSV file",id:"example-queries-to-create-input-csv-file",level:2},{value:"AWS - Athena Query",id:"aws---athena-query",level:3},{value:"GCP - BigQuery Query",id:"gcp---bigquery-query",level:3},{value:"Azure - Yarn Script",id:"azure---yarn-script",level:3}],p={toc:s};function c(e){let{components:t,...n}=e;return(0,r.kt)("wrapper",(0,a.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"In order to support the big data processing requirements that some organizations have, it may be more practical or efficient for you to compute carbon metrics within your existing processing. To do so, we support the generation of a lookup table that can be utilized as an additional step in your pipeline."),(0,r.kt)("p",null,"The lookup table maps the estimated energy (kilowatt-hours) and carbon emissions (CO2e) to 1 unit of usage, for all the unique combinations of region, service name, usage type and usage unit in the billing data of your cloud provider(s)."),(0,r.kt)("p",null,"Once generated, this lookup table (CSV file) can be deployed to your ETL or other data processing pipeline. Then when processing your billing data, you can simply multiply your usage amount by the values in the lookup tables to estimate energy and CO2e. This approach avoids having to use the Cloud Carbon Footprint application code directly, and works regardless of the programming language or environment used in your pipeline."),(0,r.kt)("p",null,"To generate this lookup table:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Make sure you have a CSV file inside the ",(0,r.kt)("inlineCode",{parentName:"li"},"cli")," package, that contains all the unique region, service name, usage type and usage unit variations in your billing data, along with the vCPUs for that line item, if it exists. You can see an example of this using AWS data ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/cloud-carbon-footprint/cloud-carbon-footprint/blob/trunk/packages/cli/src/__tests__/CreateLookupTable/aws_input.test.csv"},"here"),", and ",(0,r.kt)("a",{parentName:"li",href:"#example-queries-to-create-input-csv-file"},"below")," for example queries to create this file."),(0,r.kt)("li",{parentName:"ol"},"Run the following:")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"yarn create-lookup-table <options>\n")),(0,r.kt)("p",null,"The options for this command are:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'--awsInput <filename> (required. name of input file, e.g. "aws_input.csv")\n--awsOutput <filename> (optional, defaults to "aws_lookup_data.csv")\n--gcpInput <filename> (required. name of input file, e.g. "gcp_input.csv")\n--gcpOutput <filename> (optional, defaults to "gcp_lookup_data.csv")\n--azureInput <filename> (required. name of input file, e.g. "azure_input.csv")\n--azureOutput <filename> (optional, defaults to "azure_lookup_data.csv")\n')),(0,r.kt)("p",null,"We would like to thank ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/mfulleratlassian"},"@mfulleratlassian")," for contributing this functionality."),(0,r.kt)("h2",{id:"example-queries-to-create-input-csv-file"},"Example queries to create input CSV file"),(0,r.kt)("h3",{id:"aws---athena-query"},"AWS - Athena Query"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"SELECT \nline_item_product_code as serviceName,\nproduct_region as region,\nline_item_usage_type as usageType,\npricing_unit as usageUnit,\nproduct_vcpu as vCpus\nFROM <your-cost-and-usage-reports-table>\nWHERE line_item_line_item_type IN ('Usage', 'DiscountedUsage', 'SavingsPlanCoveredUsage')\nAND line_item_usage_start_date >= DATE('YYYY-MM-DD')\nAND line_item_usage_start_date <= DATE('YYYY-MM-DD')\nGROUP BY 1, 2, 3, 4, 5\n")),(0,r.kt)("h3",{id:"gcp---bigquery-query"},"GCP - BigQuery Query"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"SELECT\nservice.description as serviceName,\nifnull(location.region, location.location) as region,\nsku.description as usageType,\nusage.unit as usageUnit,\nsystem_labels.value AS machineType\nFROM <your-billing-export-table>\nLEFT JOIN\nUNNEST(system_labels) AS system_labels\nON system_labels.key = \"compute.googleapis.com/machine_spec\"\nWHERE cost_type != 'rounding_error'\nAND usage.unit IN ('byte-seconds', 'seconds', 'bytes')\nAND usage_start_time >= TIMESTAMP('YYYY-MM-DD')\nAND usage_end_time <= TIMESTAMP('YYYY-MM-DD')\nGROUP BY serviceName, region, usageType, usageUnit, machineType\n")),(0,r.kt)("h3",{id:"azure---yarn-script"},"Azure - Yarn Script"),(0,r.kt)("p",null,"Creating an input file for Azure using billing data requires the use of the Consumption Management API rather than a direct query.\nTo assist with this, we have created a script that makes use of your configured ",(0,r.kt)("a",{parentName:"p",href:"/docs/azure"},"credentials")," in the ",(0,r.kt)("inlineCode",{parentName:"p"},"packages/cli/.env")," file to query and output the needed mappings to a CSV file."),(0,r.kt)("p",null,"To use this script, run the following yarn command with the provided parameters:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"yarn create-azure-lookup <options>\n")),(0,r.kt)("p",null,"The options for this command are:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'--startDate <YYYY-MM-DD> (optional, defaults to 30 days prior to endDate)\n--endDate <YYYY-MM-DD> (optional, defaults to current date)\n--output <filename> (optional, defaults to "azure_input.csv")\n')))}c.isMDXComponent=!0}}]);