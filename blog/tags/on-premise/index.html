<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-tags-post-list-page plugin-blog plugin-id-default">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">One post tagged with &quot;on-premise&quot; | Cloud Carbon Footprint</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://cloud-carbon-footprint.github.io/blog/tags/on-premise"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" property="og:title" content="One post tagged with &quot;on-premise&quot; | Cloud Carbon Footprint"><meta data-rh="true" name="docusaurus_tag" content="blog_tags_posts"><meta data-rh="true" name="docsearch:docusaurus_tag" content="blog_tags_posts"><link data-rh="true" rel="icon" href="/img/favicon.png"><link data-rh="true" rel="canonical" href="https://cloud-carbon-footprint.github.io/blog/tags/on-premise"><link data-rh="true" rel="alternate" href="https://cloud-carbon-footprint.github.io/blog/tags/on-premise" hreflang="en"><link data-rh="true" rel="alternate" href="https://cloud-carbon-footprint.github.io/blog/tags/on-premise" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://L8RY6HBDJZ-dsn.algolia.net" crossorigin="anonymous"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Cloud Carbon Footprint RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Cloud Carbon Footprint Atom Feed">



<link rel="search" type="application/opensearchdescription+xml" title="Cloud Carbon Footprint" href="/opensearch.xml"><link rel="stylesheet" href="/assets/css/styles.c3e29cd2.css">
<link rel="preload" href="/assets/js/runtime~main.6ae563cd.js" as="script">
<link rel="preload" href="/assets/js/main.8fe9b0da.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function e(e){document.documentElement.setAttribute("data-theme",e)}var t=function(){var e=null;try{e=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(e){}return e}()||function(){var e=null;try{e=localStorage.getItem("theme")}catch(e){}return e}();null!==t?e(t):window.matchMedia("(prefers-color-scheme: dark)").matches?e("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,e("light"))}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.png" alt="My Site Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/logo.png" alt="My Site Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Cloud Carbon Footprint</b></a><a class="navbar__item navbar__link navbar__link" href="/docs/getting-started">Get Started</a><a class="navbar__item navbar__link navbar__link" href="/docs/">Docs</a><a href="https://demo.cloudcarbonfootprint.org/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link navbar__link">Demo</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a><a href="https://github.com/cloud-carbon-footprint/cloud-carbon-footprint" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link navbar__link">Github</a></div><div class="navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">Recent posts</div><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/on-prem-data-collection">CCF Data Collection: On-Premise</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/ccf-on-vm">Running and Deploying CCF in a Virtual Machine</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><header class="margin-bottom--xl"><h1>One post tagged with &quot;on-premise&quot;</h1><a href="/blog/tags">View All Tags</a></header><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/blog/on-prem-data-collection">CCF Data Collection: On-Premise</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2023-09-07T00:00:00.000Z" itemprop="datePublished">September 7, 2023</time> ¬∑ <!-- -->12 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><span itemprop="name">Kenneth Sambrook</span></div><small class="avatar__subtitle" itemprop="description">Senior Software Engineer (Security) @ Electronic Arts</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><h2 class="anchor anchorWithStickyNavbar_LWe7" id="forward">Forward<a href="#forward" class="hash-link" aria-label="Direct link to Forward" title="Direct link to Forward">‚Äã</a></h2><p>Embarking on the journey of collecting data for your on-premise resources can at first seem like an impossible task. What data do I actually need? Do you have the right tooling? What stakeholders are you going to need, and how much time is this going to take? Where do you store the data? Most importantly, how do you get the data once you identify the tooling available to you? We‚Äôll cover all of that below, but first just know that despite your initial trepidation; endpoint data exists in countless tools. With a little creativity and knowhow, you should have no trouble identifying, retrieving, and storing endpoint data to be utilized within the CCF Dashboard..</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="getting-started-with-on-premise-data-collection">Getting Started With On-Premise Data Collection<a href="#getting-started-with-on-premise-data-collection" class="hash-link" aria-label="Direct link to Getting Started With On-Premise Data Collection" title="Direct link to Getting Started With On-Premise Data Collection">‚Äã</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="the-on-premise-data-model">The On-premise data model<a href="#the-on-premise-data-model" class="hash-link" aria-label="Direct link to The On-premise data model" title="Direct link to The On-premise data model">‚Äã</a></h3><p>The CCF CLI takes in on-premise data using a predefined model. This model dictates the type, content, and format of the data needed in order to facilitate and proper and accurate data import and manipulation. You can view the current custom data model, as well as methodology write ups in the <a href="https://www.cloudcarbonfootprint.org/docs/on-premise/" target="_blank" rel="noopener noreferrer">On-Premise</a> parts of the CCF docs . The data model contains a lot of common fields such as CPU cores, memory, and where in the world a particular machine is located. We‚Äôll cover these in more detail as we continue on, however just keep in mind that we need all of this data for each endpoint to provide accurate estimates.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="data-sources">Data Sources<a href="#data-sources" class="hash-link" aria-label="Direct link to Data Sources" title="Direct link to Data Sources">‚Äã</a></h3><p>Your organization will most likely contain a multitude of sources from which endpoint data can originate. From computer accounts in Active Directory to System information stored within tools such as your Antivirus or system patching tools; large swathes of data are stored. It‚Äôs in these places you‚Äôll be looking for your target endpoints and pulling relevant data from these sources to populate the On-Premise data model.</p><p>Endpoint data can also come from some unlikely places. If you are finding yourself lost in your search for endpoint data, think of the following list of tooling to see if perhaps your IT department has one of these tools:</p><ul><li>Antivirus suites</li><li>Vulnerability management suites</li><li>CMDB applications (Inventory management)</li><li>Configuration management suites<ul><li>Puppet</li><li>Chef</li><li>SCCM</li><li>MEM</li></ul></li><li>System monitoring suites<ul><li>Nagios</li><li>Cacti</li><li>Grafana<ul><li>Node Exporter</li><li>Telegraf</li><li>Prometheus Databases</li></ul></li></ul></li></ul><p>The list goes on and on. There are countless tools currently available for organizations to perform a wide range of tasks related to endpoint management, monitoring, and protection. The wonderful thing about tooling such as this is that they also rely on large amounts of data related to the endpoint. Antivirus tools need to know if the machine has been online and communicating with the management console for updates and status information. Monitoring tools rely solely on doing exactly what their name suggests‚Äìmonitoring endpoints. CMDB tools are directly responsible for endpoint and inventory management. Many IT departments consider CMDB tooling a source of endpoint and inventory truth. Data here is likely to be very accurate.</p><font size="1">NOTE: Keep in mind the permissions needed to access these data sources, and ensure you‚Äôre following your company&#x27;s best practices on the retrieval and storage of this data. Where possible, always partner with the data source owner to ensure you‚Äôre not only getting the best data, but handling it in a manner that doesn‚Äôt expose your company to unnecessary risks or security incidents.</font><br><p>Data sources are the most important part of embarking on a journey of tracking and estimating the environmental impacts of your enterprise. As you begin, be creative and leverage your existing partnerships with various departments within your organization to find these unlikely sources of data. Continue to rely on the On-premise Data Model to match data sources with the required fields.</p><p>When choosing a data source, be mindful of the size of the dataset, and your ability to continually pull data out. Intermittent, or services with unreliable uptimes are not preferable sources. Data sources with large datasets that cannot be filtered or compressed may prove difficult or costly to ingest. Always try to choose data sources that have exposed API‚Äôs if possible. This will make automating and scheduling data collection far simpler in the long run. If API‚Äôs are simply not possible, strive instead for tooling that can generate scheduled reports containing the data you need. If possible opt for CSV, JSON, XML outputs that you can use easily with your data collection and storage processes. We‚Äôll cover this in the section <em>Collecting on-premise data</em>.</p><p>Before we move on to the means and methods in which you might collect and store this data, bear in mind that some of the fields in the On-premise Data Model are to be collected over time. We will go into greater detail about these fields later on. Just understand that your chosen data source does not necessarily have to include this data. You may be able to generate the data with good automation, and scheduled data retrieval from other information provided by the data source.</p><ul><li>dailyUptime</li><li>weeklyUptime</li><li>monthlyUptime</li><li>annualUptime</li></ul><p>Once you have a source of data to utilize, you‚Äôll be using that data to calculate the above fields.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="data-collection-and-storage-technologies">Data Collection and Storage Technologies<a href="#data-collection-and-storage-technologies" class="hash-link" aria-label="Direct link to Data Collection and Storage Technologies" title="Direct link to Data Collection and Storage Technologies">‚Äã</a></h3><p>For example‚Äôs sake, let‚Äôs say you have chosen your AntiVirus as your initial data source. This tool contains all the basic information needed for the On-premise Data Model, and it has a robust REST API that can be utilized to fetch the data. Where do we go from here? Let‚Äôs have a look at a basic workflow diagram.</p><p><img loading="lazy" alt="Workflow Diagram" src="/assets/images/ccf_on_prem_blog_img_1-89a595ff6d485f7f59893e93ad132121.png" width="2000" height="190" class="img_ev3q"></p><p>This is the simplest possible way to represent the actions to be taken when it comes to collecting and storing data. Although simple to visualize, the means in which you achieve this goal can grow from very simple to very complex depending on the amount of data you will have, the length of time you‚Äôll be holding onto it, and any security or risk considerations being taken into account. As with data sources, there are countless tools and techniques one can use to perform these actions.</p><p>Because we‚Äôll need to capture this data over time, choose a data collection technology that allows for accurate and timely scheduled runs. Being able to collect data, daily, or by hour will greatly improve the accuracy of your data.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="aws-glue-with-aws-s3-data-lake">AWS Glue with AWS S3 Data Lake<a href="#aws-glue-with-aws-s3-data-lake" class="hash-link" aria-label="Direct link to AWS Glue with AWS S3 Data Lake" title="Direct link to AWS Glue with AWS S3 Data Lake">‚Äã</a></h4><p>This is an excellent cloud native approach to capturing large to extremely large amounts of data easily. AWS Glue provides capabilities such as scheduled, and interval based run initialization and the S3 Datalake can handle extremely large amounts of data.</p><p>Additionally you can pair this with AWS functionality such as AWS Athena, RDS, and Lambda to make transforming, and retrieving the data simple, effective, and accurate.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="django-with-django-rest-framework-celery-beat-and-postgresql">Django with Django-Rest-Framework, Celery-Beat, and PostgreSQL<a href="#django-with-django-rest-framework-celery-beat-and-postgresql" class="hash-link" aria-label="Direct link to Django with Django-Rest-Framework, Celery-Beat, and PostgreSQL" title="Direct link to Django with Django-Rest-Framework, Celery-Beat, and PostgreSQL">‚Äã</a></h4><p>If you have a Python developer available and are interested in a cost effective, or free solution; open source may be your best choice. Django is an extremely robust web framework built on the ‚ÄúView-Model‚Äù strategy. It contains an impressive number of built in capabilities including ‚ÄúCRUD‚Äù functionality which makes creating, and using database models a breeze.</p><p>With the addition of 2 additional plugins it can provide all the data storage and retrieval functionality you would need. Django-Rest-Framework makes creating API‚Äôs within Django simple, thus aiding in retrieving your stored data. Celery-Beat is a database-backed task scheduler that can make scheduling accurate and timely data collection a breeze.</p><p>Django also works incredibly well within containerized environments such as Docker, and Kubernetes.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="on-premise-data---data-model">On-premise Data - Data Model<a href="#on-premise-data---data-model" class="hash-link" aria-label="Direct link to On-premise Data - Data Model" title="Direct link to On-premise Data - Data Model">‚Äã</a></h3><p>Much of the data you‚Äôll be collecting is very straightforward. Machine name, CPU type and memory count may be readily available. Some of the data however requires special consideration. Let‚Äôs explore those briefly.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="special-data-model-fields">Special Data Model Fields<a href="#special-data-model-fields" class="hash-link" aria-label="Direct link to Special Data Model Fields" title="Direct link to Special Data Model Fields">‚Äã</a></h4><p>The below data points will require special care when collecting the data. Take care to ensure that you build these considerations into your data model to ensure an accurate data collection process.</p><ul><li>machineType:<ul><li>Different machine types will generate different power loads. The formula used in calculating power draw for different types of machines will vary based on the type. If your data source includes a type, you should ensure that it is formatted to be either ‚Äúserver‚Äù, ‚Äúlaptop‚Äù, or ‚Äúdesktop‚Äù. Being unable to provide this information will impact the accuracy of your power usage calculations.</li></ul></li><li>cpuUtilization:<ul><li>Your data collection tool may be unable to provide this information. If that is the case, your best option is to make a best case estimation.</li></ul></li><li>[daily,weekly,monthly,annual]<!-- -->Uptime:<ul><li>These 4 fields are the most important, and also require a good data collection process. Using your data sources, you‚Äôll need to provide incremental totals for these fields using uptime data if available. Not being able to provide this data will lead to very inaccurate carbon impact estimations.</li></ul></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="collecting-on-premise-data">Collecting On-premise Data<a href="#collecting-on-premise-data" class="hash-link" aria-label="Direct link to Collecting On-premise Data" title="Direct link to Collecting On-premise Data">‚Äã</a></h2><p>Once you‚Äôve identified a suitable data source and method, you can now begin the process of collecting and storing your on-premise data. For the purposes of the write-up we‚Äôre going to use an ‚ÄúAntivirus‚Äù as our data source.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="the-data-source---antivirus">The Data Source - Antivirus<a href="#the-data-source---antivirus" class="hash-link" aria-label="Direct link to The Data Source - Antivirus" title="Direct link to The Data Source - Antivirus">‚Äã</a></h3><p>Our data source is an Antivirus suite that provides up to the minute endpoint stats that cover all of the basic sources.</p><ul><li>cpuDescription</li><li>memory</li><li>machineType (Server, Laptop, Desktop)</li><li>machineName</li></ul><p>In addition to the basics, the data source also has some additional data which will prove useful to use later on.</p><ul><li>lastAgentCommunication<ul><li>This tells us when the endpoint was last online. It will be useful in determining system uptime.</li></ul></li><li>agentPublicIP<ul><li>Knowing the country and region where an endpoint resides, helps us calculate carbon intensity. The public IP can be used to identify the geolocation data associated with the agent to put this into practice.</li></ul></li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="collecting-the-data">Collecting the data<a href="#collecting-the-data" class="hash-link" aria-label="Direct link to Collecting the data" title="Direct link to Collecting the data">‚Äã</a></h4><p>To make things easier for us, our data source also provides a REST API in which we can collect the data in real time. If your data source doesn‚Äôt provide an API, attempt to get regular reports in CSV, XML, or JSON format that you can use in lieu of making API requests.</p><p>Depending on the method of data collection and storage you‚Äôve chosen, some coding is most likely going to be required. It would be extremely beneficial to enlist the help of a developer or data engineer to assist you in reliably collecting and storing this data. Having the ability to retrieve and parse data from an API, work with S3 or a simple database, and create basic automations will come in handy throughout this process. Remember the illustration above.</p><p><img loading="lazy" alt="Workflow Diagram" src="/assets/images/ccf_on_prem_blog_img_1-89a595ff6d485f7f59893e93ad132121.png" width="2000" height="190" class="img_ev3q"></p><p>You‚Äôll want to ensure that whatever method you‚Äôve chosen for data collection, that you‚Äôre able to perform the collection at a set timed interval. Tracking machine uptime is paramount to being successful here.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="calculating-uptime-hours">Calculating upTime hours<a href="#calculating-uptime-hours" class="hash-link" aria-label="Direct link to Calculating upTime hours" title="Direct link to Calculating upTime hours">‚Äã</a></h4><p>A number of fields in the On-premise Data Model, represent uptime hours of your agent over a period of time. As you collect uptime information about your endpoints, you will want to populate these fields and increment each individual counter.</p><p>Each uptime counter represents a historical period of time. Daily, weekly, yearly, as well as perhaps 30, 60, 90 day increments. These fields may be present in your data source from day one, but perhaps you may need to create and calculate these.</p><p><img loading="lazy" alt="Uptime Diagram" src="/assets/images/ccf_on_prem_blog_img_2-a9e508da4ae357fd9bbec52caa06bf26.png" width="2002" height="398" class="img_ev3q"></p><p>In the diagram above is an oversimplified view of a data collection event for a single endpoint. Let&#x27;s say for instance the counter you&#x27;re incrementing is the <strong>dailyUptime</strong> counter. As data about the endpoint comes in it‚Äôs determined that the endpoint has been online in the last 1 hour. To increment the daily counter we first need to check the timestamp of when the counter was last reset. If the counter is less than 24 hours old, then we can increment the counter by 1 hour. If it is older than 24 hours we should reset the counter to 1. Additionally you should also reset the timestamp to a current date and time.</p><p>Here is a quick sample of pseudo code to illustrate a couple of these use cases.</p><p><strong>Increment Daily Uptime Counters</strong></p><p><img loading="lazy" alt="Daily Uptime Code Snippet" src="/assets/images/ccf_on_prem_blog_img_5-d94de4a51b869063e2821e011c9c0577.png" width="1354" height="456" class="img_ev3q"></p><p><strong>Increment 30 Day Uptime Counters</strong></p><p><img loading="lazy" alt="Monthly Uptime Code Snippet" src="/assets/images/ccf_on_prem_blog_img_6-9e884cedd79a1c4ca8148c5ad0f90093.png" width="1342" height="470" class="img_ev3q"></p><p>This same principle applies to all other values related to uptime. <strong>weeklyUptime</strong>, <strong>monthlyUptime</strong>, and <strong>yearlyUptime</strong> can all be calculated this way. You can also add additional uptime counters as you see fit; however ensure that the required uptime fields from the On-premise Data Model are present.</p><p>When creating the initial timestamps always remember to start the timestamp from the moment the machine was first added to the data model. It is not advisable to to create an arbitrary initial timestamp as this can cause your uptime fields to be wildly inaccurate.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">‚Äã</a></h2><p>Collecting on-premise data for activities such as patching, inventory, and lifecycle management has been happening across IT organizations for a very long time. An incredible amount of work has gone into the development and deployment of tooling to achieve those goals. As the world moves more towards implementing green initiatives to better shape their technology futures, being able to calculate and report on the environmental impact of our infrastructures grows as well.</p><p>Even though you may not have a fit for purpose tool to collect on-premise data, that doesn‚Äôt mean you can‚Äôt still get the data you need. This data most likely already exists in many other tools already in use by your organization. The Anti-Virus used in this post is clearly not meant for this task, but with a bit of trial and error, it can do exactly what is needed to gather all of the necessary data. Be creative and keep an open mind. Data exists everywhere.</p><font size="1">This paper represents an exploratory project undertaken by EA employees to explore ways to leverage existing data and automate methods to calculate electricity use and emissions associated with on-premise endpoints. The statements and opinions expressed in this article are those of the author and do not represent how EA calculates emissions and do not constitute or imply an endorsement of a product, process or service.</font></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/electronicarts">electronicarts</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/data">data</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/on-premise">on-premise</a></li></ul></div></footer></article><nav class="pagination-nav" aria-label="Blog list page navigation"></nav></main></div></div></div><div><div class="footerLicenseContainer_aMKa"><a class="footerLicenseLink_V4Yd signature_Phj5" target="_blank" href="https://www.thoughtworks.com">Made for the üåé by Thoughtworks</a><p>Cloud Carbon Footprint is an open-source project, sponsored by Thoughtworks Inc. under the¬†<a class="footerLicenseLink_V4Yd undefined" target="_blank" href="http://www.apache.org/licenses/LICENSE-2.0">Apache License, Version 2.0</a></p><p><a class="footerLicenseLink_V4Yd undefined" target="_blank" href="https://www.thoughtworks.com/privacy-policy">PRIVACY POLICY</a></p></div></div></div>
<script src="/assets/js/runtime~main.6ae563cd.js"></script>
<script src="/assets/js/main.8fe9b0da.js"></script>
</body>
</html>